{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0fce81c",
   "metadata": {},
   "source": [
    "# Introduction to Google's ADK - Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c29a1f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dba70d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-CAX1RmewpwkaberClG64zOk6tulvx', created=1756626253, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_cbf1785567', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Yes, I'm ready! How can I assist you today?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=13, prompt_tokens=27, total_tokens=40, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "\n",
      " OpenAI is ready\n"
     ]
    }
   ],
   "source": [
    "MODEL_GPT = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT)\n",
    "llm_small = LiteLlm(model=\"openai/gpt-4o-mini\")\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, \n",
    "                                messages=[{\"role\": \"user\", \n",
    "                                           \"content\": \"Are you ready?\"}], \n",
    "                                tools=[]))\n",
    "\n",
    "\n",
    "print(\"\\n OpenAI is ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1293d",
   "metadata": {},
   "source": [
    "## 3.2. Explore `neo4j_for_adk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09d28cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_for_adk import graphdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4a2ea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'query_result': [{'message1': 'Neo4j is Ready!'}]}\n"
     ]
    }
   ],
   "source": [
    "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message1\")\n",
    "\n",
    "print(neo4j_is_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "898e2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wish(name: Optional[str] = \"User\") -> str:\n",
    "    \"\"\"Function to wish the user.\"\"\"\n",
    "    return f\"Hello, {name}! How can I assist you today?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53bf4af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, Rajesh! How can I assist you today?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wish(\"Rajesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3e9b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a basic tool -- send a parameterized cypher query\n",
    "def say_hello(person_name: str) -> dict:\n",
    "    \"\"\"Formats a welcome message to a named person. \n",
    "\n",
    "    Args:\n",
    "        person_name (str): the name of the person saying hello\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the results of the query.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'query_result' key with an array of result rows.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    return graphdb.send_query(\"RETURN 'Hello to you, ' + $person_name AS reply\",\n",
    "    {\n",
    "        \"person_name\": person_name\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f0f012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'query_result': [{'reply': 'Hello to you, Rajesh Thakur'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "say_hello(\"Rajesh Thakur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df19a280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'query_result': [{'reply': 'Hello to you, RETURN Rajesh Thakur'}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "say_hello(\"RETURN Rajesh Thakur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f068021f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'hello_agent_v1' created.\n"
     ]
    }
   ],
   "source": [
    "# Define the Cypher Agent\n",
    "hello_agent = Agent(\n",
    "    name=\"hello_agent_v1\",\n",
    "    model=llm_small, # defined earlier in a variable\n",
    "    description=\"Has friendly chats with a user.\",\n",
    "    instruction=\"\"\"You are a helpful assistant, chatting with a user. \n",
    "                Be polite and friendly, introducing yourself and asking who the user is. \n",
    "\n",
    "                If the user provides their name, use the 'say_hello' tool to get a custom greeting.\n",
    "                If the tool returns an error, inform the user politely. \n",
    "                If the tool is successful, present the reply.\n",
    "                \"\"\",\n",
    "    tools=[say_hello], # Pass the function directly\n",
    ")\n",
    "\n",
    "print(f\"Agent '{hello_agent.name}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eae89d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'hello_agent_v1' created.\n"
     ]
    }
   ],
   "source": [
    "# Define the Cypher Agent\n",
    "hello_agent1 = Agent(\n",
    "    name=\"hello_agent_v2\",\n",
    "    model=llm_small, # defined earlier in a variable\n",
    "    description=\"Has friendly chats with a user.\",\n",
    "    instruction=\"\"\"You are a helpful assistant, chatting with a user. \n",
    "                Be polite and friendly, introducing yourself and asking who the user is. \n",
    "\n",
    "                If the user provides their name, use the 'say_hello' tool to get a custom greeting.\n",
    "                If the tool returns an error, inform the user politely. \n",
    "                If the tool is successful, present the reply.\n",
    "                \"\"\",\n",
    "    tools=[say_hello], # Pass the function directly\n",
    ")\n",
    "\n",
    "print(f\"Agent '{hello_agent.name}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514dcdde",
   "metadata": {},
   "source": [
    "# Run The Agent\n",
    "\n",
    "To run an agent, you'll need some additional components namely an execution environment and memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17309dfc",
   "metadata": {},
   "source": [
    "### Create the Runner and SessionService\n",
    "\n",
    "\n",
    "Let's assume we have a single user talking to the agent in a single session. Let's create this user, the session and the runner:\n",
    "* `SessionService`: Responsible for managing conversation history and state for different users and sessions. The `InMemorySessionService` is a simple implementation that stores everything in memory, suitable for testing and simple applications. It keeps track of the messages exchanged.  \n",
    "* `Runner`: The engine that orchestrates the interaction flow. It takes user input, routes it to the appropriate agent, manages calls to the LLM and tools based on the agent's logic, handles session updates via the `SessionService`, and yields events representing the progress of the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7dca91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name = hello_agent.name + \"_app\"\n",
    "user_id = hello_agent.name + \"_user_1\"\n",
    "session_id = hello_agent.name + \"_session_1\"\n",
    "\n",
    "\n",
    "# Initialize a session service and a session\n",
    "session_service = InMemorySessionService()\n",
    "await session_service.create_session(app_name = app_name,\n",
    "                                    user_id = user_id,\n",
    "                                    session_id = session_id)\n",
    "\n",
    "# Create the runner\n",
    "runner = Runner(\n",
    "    agent = hello_agent,\n",
    "    app_name = app_name,\n",
    "    session_service = session_service\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f59424",
   "metadata": {},
   "source": [
    "# Run the Agent\n",
    "\n",
    "\n",
    "Here's what's happening:\n",
    " \n",
    "1. Package the user query into the ADK `Content` format.\n",
    "2. Call`runner.run_async` (providing it with user/session context and the new message)\n",
    "4. Iterate through the **Events** yielded by the runner. Events represent steps in the agent's execution (e.g., tool call requested, tool result received, intermediate LLM thought, final response).  \n",
    "5. Identify and print the **final response** event using `event.is_final_response()`.\n",
    "\n",
    "**Why `async`?** Interactions with LLMs and potentially tools (like external APIs) are I/O-bound operations. Using `asyncio` allows the program to handle these operations efficiently without blocking execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bb8c60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Event] Author: hello_agent_v1, Type: Event, Final: False, Content: parts=[Part(\n",
      "  function_call=FunctionCall(\n",
      "    args={\n",
      "      'person_name': 'Rajesh Thakur'\n",
      "    },\n",
      "    id='call_HtVq31j7Z7UrwwZX6Aa6gpfi',\n",
      "    name='say_hello'\n",
      "  )\n",
      ")] role='model'\n",
      "  [Event] Author: hello_agent_v1, Type: Event, Final: False, Content: parts=[Part(\n",
      "  function_response=FunctionResponse(\n",
      "    id='call_HtVq31j7Z7UrwwZX6Aa6gpfi',\n",
      "    name='say_hello',\n",
      "    response={\n",
      "      'query_result': [\n",
      "        {\n",
      "          'reply': 'Hello to you, Rajesh Thakur'\n",
      "        },\n",
      "      ],\n",
      "      'status': 'success'\n",
      "    }\n",
      "  )\n",
      ")] role='user'\n",
      "  [Event] Author: hello_agent_v1, Type: Event, Final: True, Content: parts=[Part(\n",
      "  text=\"Hello to you, Rajesh Thakur! It's great to meet you. How can I assist you today?\"\n",
      ")] role='model'\n",
      "<<< Agent Response: Hello to you, Rajesh Thakur! It's great to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Hello, I'm Rajesh Thakur.\"\n",
    "\n",
    "content = types.Content(role='user', parts=[types.Part(text=user_message)])\n",
    "\n",
    "final_response_text = \"Agent did not produce a final response.\" # Default will be replaced if the agent produces a final response.\n",
    "\n",
    "verbose = True\n",
    "\n",
    "async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "    if verbose:\n",
    "        print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "    if event.is_final_response():\n",
    "        if event.content and event.content.parts:\n",
    "            final_response_text = event.content.parts[0].text ## # Assuming text response in the first part\n",
    "\n",
    "        elif event.actions and event.actions.escalate:\n",
    "            final_response_text = f\"Agent escalated: {event.error_message or 'No specific message provided.'}\"\n",
    "        break\n",
    "print(f\"<<< Agent Response: {final_response_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e7ed70",
   "metadata": {},
   "source": [
    "# Create Helper Class: AgentCaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_caller = AgentCaller(agent, runner, user_id, session_id)\n",
    "# agent_caller1 = AgentCaller(agent1, runner1, user_id1, session_id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9bfdad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentCaller:\n",
    "    \"\"\"A simple wrapper class for interacting with an ADK agent.\"\"\"\n",
    "    \n",
    "    def __init__(self, agent: Agent, runner: Runner, \n",
    "                 user_id: str, session_id: str):\n",
    "        \"\"\"Initialize the AgentCaller with required components.\"\"\"\n",
    "        self.agent = agent\n",
    "        self.runner = runner\n",
    "        self.user_id = user_id\n",
    "        self.session_id = session_id\n",
    "\n",
    "\n",
    "    def get_session(self):\n",
    "        return self.runner.session_service.get_session(app_name=self.runner.app_name, user_id=self.user_id, session_id=self.session_id)\n",
    "\n",
    "    \n",
    "    async def call(self, user_message: str, verbose: bool = False):\n",
    "        \"\"\"Call the agent with a query and return the response.\"\"\"\n",
    "        print(f\"\\n>>> User Message: {user_message}\")\n",
    "\n",
    "        # Prepare the user's message in ADK format\n",
    "        content = types.Content(role='user', parts=[types.Part(text=user_message)])\n",
    "\n",
    "        final_response_text = \"Agent did not produce a final response.\" \n",
    "        \n",
    "        # Key Concept: run_async executes the agent logic and yields Events.\n",
    "        # We iterate through events to find the final answer.\n",
    "        async for event in self.runner.run_async(user_id=self.user_id, session_id=self.session_id, new_message=content):\n",
    "            # You can uncomment the line below to see *all* events during execution\n",
    "            if verbose:\n",
    "                print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "            # Key Concept: is_final_response() marks the concluding message for the turn.\n",
    "            if event.is_final_response():\n",
    "                if event.content and event.content.parts:\n",
    "                    # Assuming text response in the first part\n",
    "                    final_response_text = event.content.parts[0].text\n",
    "                elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "                    final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "                break # Stop processing events once the final response is found\n",
    "\n",
    "        print(f\"<<< Agent Response: {final_response_text}\")\n",
    "        return final_response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ab67caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def make_agent_caller(agent: Agent, initial_state: Optional[Dict[str, Any]] = {}) -> AgentCaller:\n",
    "    \"\"\"Create and return an AgentCaller instance for the given agent.\"\"\"\n",
    "    app_name = agent.name + \"_app\"\n",
    "    user_id = agent.name + \"_user\"\n",
    "    session_id = agent.name + \"_session_01\"\n",
    "    \n",
    "    # Initialize a session service and a session\n",
    "    session_service = InMemorySessionService()\n",
    "    await session_service.create_session(\n",
    "        app_name=app_name,\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        state=initial_state\n",
    "    )\n",
    "    \n",
    "    runner = Runner(\n",
    "        agent=agent,\n",
    "        app_name=app_name,\n",
    "        session_service=session_service\n",
    "    )\n",
    "    \n",
    "    return AgentCaller(agent, runner, user_id, session_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68995d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_agent_caller = await make_agent_caller(hello_agent)\n",
    "hello_agent_caller1 = await make_agent_caller(hello_agent1)\n",
    "async def run_conversation():\n",
    "    await hello_agent_caller.call(\"Hello I'm ABK\", verbose=True)\n",
    "\n",
    "    await hello_agent_caller.call(\"I am excited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48820131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Message: Hello I'm ABK\n",
      "  [Event] Author: hello_agent_v1, Type: Event, Final: False, Content: parts=[Part(\n",
      "  function_call=FunctionCall(\n",
      "    args={\n",
      "      'person_name': 'ABK'\n",
      "    },\n",
      "    id='call_wr0aZJNZ4Ymp084YfYvOwPpv',\n",
      "    name='say_hello'\n",
      "  )\n",
      ")] role='model'\n",
      "  [Event] Author: hello_agent_v1, Type: Event, Final: False, Content: parts=[Part(\n",
      "  function_response=FunctionResponse(\n",
      "    id='call_wr0aZJNZ4Ymp084YfYvOwPpv',\n",
      "    name='say_hello',\n",
      "    response={\n",
      "      'query_result': [\n",
      "        {\n",
      "          'reply': 'Hello to you, ABK'\n",
      "        },\n",
      "      ],\n",
      "      'status': 'success'\n",
      "    }\n",
      "  )\n",
      ")] role='user'\n",
      "  [Event] Author: hello_agent_v1, Type: Event, Final: True, Content: parts=[Part(\n",
      "  text=\"Hello to you, ABK! It's great to meet you. How can I assist you today?\"\n",
      ")] role='model'\n",
      "<<< Agent Response: Hello to you, ABK! It's great to meet you. How can I assist you today?\n",
      "\n",
      ">>> User Message: I am excited\n",
      "<<< Agent Response: That's wonderful to hear, ABK! Excitement is always a great feeling. Whatâ€™s got you all excited today?\n"
     ]
    }
   ],
   "source": [
    "await run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ab047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"ff8081819782e69e0198fe9c0e627a1d\",\"name\":\"Apple MacBook Pro 16\",\"createdAt\":\"2025-08-31T05:31:36.930+00:00\",\"data\":{\"year\":2019,\"price\":1849.99,\"CPU model\":\"Intel Core i9\",\"Hard disk size\":\"1 TB\"}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a68a418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
